{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Immigration-&amp;-Weather-Pipeline---Data-Engineering-Capstone-Project\" data-toc-modified-id=\"Immigration-&amp;-Weather-Pipeline---Data-Engineering-Capstone-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Immigration &amp; Weather Pipeline - Data Engineering Capstone Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Project-Summary\" data-toc-modified-id=\"Project-Summary-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Project Summary</a></span></li><li><span><a href=\"#Step-1:-Scope-the-Project-and-Gather-Data\" data-toc-modified-id=\"Step-1:-Scope-the-Project-and-Gather-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Step 1: Scope the Project and Gather Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scope\" data-toc-modified-id=\"Scope-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Scope</a></span></li><li><span><a href=\"#Describe-and-Gather-Data\" data-toc-modified-id=\"Describe-and-Gather-Data-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Describe and Gather Data</a></span></li></ul></li><li><span><a href=\"#Step-2:-Explore-and-Assess-the-Data\" data-toc-modified-id=\"Step-2:-Explore-and-Assess-the-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Step 2: Explore and Assess the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Explore-the-Data\" data-toc-modified-id=\"Explore-the-Data-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Explore the Data</a></span></li><li><span><a href=\"#Cleaning-Steps\" data-toc-modified-id=\"Cleaning-Steps-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Cleaning Steps</a></span></li></ul></li><li><span><a href=\"#Step-3:-Define-the-Data-Model\" data-toc-modified-id=\"Step-3:-Define-the-Data-Model-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Step 3: Define the Data Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Conceptual-Data-Model\" data-toc-modified-id=\"3.1-Conceptual-Data-Model-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>3.1 Conceptual Data Model</a></span></li><li><span><a href=\"#3.2-Mapping-Out-Data-Pipelines\" data-toc-modified-id=\"3.2-Mapping-Out-Data-Pipelines-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>3.2 Mapping Out Data Pipelines</a></span></li></ul></li><li><span><a href=\"#Step-4:-Run-Pipelines-to-Model-the-Data\" data-toc-modified-id=\"Step-4:-Run-Pipelines-to-Model-the-Data-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Step 4: Run Pipelines to Model the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-Create-the-data-model\" data-toc-modified-id=\"4.1-Create-the-data-model-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>4.1 Create the data model</a></span></li><li><span><a href=\"#4.2-Data-Quality-Checks\" data-toc-modified-id=\"4.2-Data-Quality-Checks-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>4.2 Data Quality Checks</a></span></li><li><span><a href=\"#4.3-Data-dictionary\" data-toc-modified-id=\"4.3-Data-dictionary-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>4.3 Data dictionary</a></span></li></ul></li><li><span><a href=\"#Step-5:-Complete-Project-Write-Up\" data-toc-modified-id=\"Step-5:-Complete-Project-Write-Up-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Step 5: Complete Project Write Up</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration & Weather Pipeline - Data Engineering Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config('spark.jars.packages','saurfang:spark-sas7bdat:2.0.0-s_2.11').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an ETL pipeline for the [I94 immigration dataset](https://travel.trade.gov/research/reports/i94/historical/2016.html) and world temperature dataset from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data). This will analyst to explore the data to determine if immigration is affected by the destination's temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I94 immigration dataset](https://travel.trade.gov/research/reports/i94/historical/2016.html) was retrieved from from the US National Tourism and Trade Office's site: https://travel.trade.gov/research/reports/i94/historical/2016.html. The data are broken down into files by month. Below are some relevant information contained in the data for this particular project:\n",
    "\n",
    "* `i94yr`: Year (4 digit number)\n",
    "* `i94mon`: Month as numerical value (1 or 2 digit number)\n",
    "* `i94cit`: Reference code of the city of origin (3 digit number)\n",
    "* `i94port`: Reference code of destination city airport (3 characters)\n",
    "* `arrdate`: Arrival date (SAS Date)\n",
    "* `depdate`: Departure date (SAS Date)\n",
    "* `i94visa`: Reason for immigration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[World temperature dataset](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) was retrieved from Kaggle: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data. The data are broken into separate files for different coarseness of areas (e.g. countries vs cities) but we'll specifically only look at cities. The file then specifies some of the following:\n",
    "\n",
    "* `dt`: Datetime of when temperature was recorded (YYYY-MM-DD)\n",
    "* `AverageTemperature`:  Average temperature in Celcius of area\n",
    "* `City`:  Name of city where temperature was recorded\n",
    "* `Country`:  Name of country where temperature was recorded\n",
    "* `Latitude`: Latitude of city\n",
    "* `Longitude`:  Longitude of city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_data_dir = '../../../data/18-83510-I94-Data-2016'\n",
    "# Get all files in the data directory\n",
    "sas_filenames = [f'{sas_data_dir}/{filename}' for filename in os.listdir(sas_data_dir)]\n",
    "sas_header_file = f'{sas_data_dir}/I94_SAS_Labels_Descriptions.SAS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load(sas_filenames[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_i94(i94_spark_df):\n",
    "        '''\n",
    "        Cleans i94 Spark dataframe with readable column names and proper date\n",
    "        and value formats.\n",
    "        \n",
    "        Args:\n",
    "            i94_spark_df: Spark dataframe of data from i94 dataset.\n",
    "        \n",
    "        Returns:\n",
    "            Cleaned Spark dataframe of data from i94 dataset\n",
    "        '''\n",
    "        # Format dates\n",
    "        i94_spark_df_dates = (i94_spark_df\n",
    "                                .withColumn('arrival_year', col('i94yr').cast('integer'))\n",
    "                                .withColumn('arrival_month', col('i94mon').cast('integer'))\n",
    "                                .withColumn('data_base_sas', to_date(lit('01/01/1960'), 'MM/dd/yyyy'))\n",
    "                                .withColumn('arrival_date', expr('date_add(data_base_sas, arrdate)'))\n",
    "                                .withColumn('departure_date', expr('date_add(data_base_sas, depdate)'))\n",
    "                                .drop('arrdate', 'depdate')\n",
    "        )\n",
    "        \n",
    "        # Rename columns and set integer values\n",
    "        i94_spark_df_clean = (i94_spark_df_dates\n",
    "                                .withColumn('arrival_port', col('i94port'))                              \n",
    "                                .withColumn('departure_city', col('i94cit').cast('integer'))\n",
    "                                .withColumn('mode_of_travel', col('i94mode').cast('integer'))\n",
    "                                .withColumn('city_of_origin', col('i94cit').cast('integer'))\n",
    "                                .withColumn('country_of_origin', col('i94res').cast('integer'))\n",
    "                                .withColumn('age', col('i94bir').cast('integer'))\n",
    "                                .withColumn('visa_type', col('i94visa').cast('integer'))            \n",
    "        )\n",
    "        \n",
    "        # Final selection of data and order\n",
    "        i94_spark_df_final = i94_spark_df_clean.select(\n",
    "                    col('arrival_date'),\n",
    "                    col('departure_date'),\n",
    "                    col('arrival_port'),\n",
    "                    col('city_of_origin'),\n",
    "                    col('country_of_origin'),\n",
    "                    col('mode_of_travel'),\n",
    "                    col('age'),\n",
    "                    col('visa_type')\n",
    "                )\n",
    "        \n",
    "        return i94_spark_df_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_i94(df_spark).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
