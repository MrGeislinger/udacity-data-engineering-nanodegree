{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Immigration-&amp;-Weather-Pipeline---Data-Engineering-Capstone-Project\" data-toc-modified-id=\"Immigration-&amp;-Weather-Pipeline---Data-Engineering-Capstone-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Immigration &amp; Weather Pipeline - Data Engineering Capstone Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Project-Summary\" data-toc-modified-id=\"Project-Summary-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Project Summary</a></span></li><li><span><a href=\"#Step-1:-Scope-the-Project-and-Gather-Data\" data-toc-modified-id=\"Step-1:-Scope-the-Project-and-Gather-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Step 1: Scope the Project and Gather Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scope\" data-toc-modified-id=\"Scope-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Scope</a></span></li><li><span><a href=\"#Describe-and-Gather-Data\" data-toc-modified-id=\"Describe-and-Gather-Data-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Describe and Gather Data</a></span></li></ul></li><li><span><a href=\"#Step-2:-Explore-and-Assess-the-Data\" data-toc-modified-id=\"Step-2:-Explore-and-Assess-the-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Step 2: Explore and Assess the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Explore-the-Data\" data-toc-modified-id=\"Explore-the-Data-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Explore the Data</a></span></li><li><span><a href=\"#Cleaning-Steps\" data-toc-modified-id=\"Cleaning-Steps-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Cleaning Steps</a></span></li></ul></li><li><span><a href=\"#Step-3:-Define-the-Data-Model\" data-toc-modified-id=\"Step-3:-Define-the-Data-Model-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Step 3: Define the Data Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Conceptual-Data-Model\" data-toc-modified-id=\"3.1-Conceptual-Data-Model-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>3.1 Conceptual Data Model</a></span></li><li><span><a href=\"#3.2-Mapping-Out-Data-Pipelines\" data-toc-modified-id=\"3.2-Mapping-Out-Data-Pipelines-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>3.2 Mapping Out Data Pipelines</a></span></li></ul></li><li><span><a href=\"#Step-4:-Run-Pipelines-to-Model-the-Data\" data-toc-modified-id=\"Step-4:-Run-Pipelines-to-Model-the-Data-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Step 4: Run Pipelines to Model the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-Create-the-data-model\" data-toc-modified-id=\"4.1-Create-the-data-model-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>4.1 Create the data model</a></span></li><li><span><a href=\"#4.2-Data-Quality-Checks\" data-toc-modified-id=\"4.2-Data-Quality-Checks-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>4.2 Data Quality Checks</a></span></li><li><span><a href=\"#4.3-Data-dictionary\" data-toc-modified-id=\"4.3-Data-dictionary-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>4.3 Data dictionary</a></span></li></ul></li><li><span><a href=\"#Step-5:-Complete-Project-Write-Up\" data-toc-modified-id=\"Step-5:-Complete-Project-Write-Up-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Step 5: Complete Project Write Up</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration & Weather Pipeline - Data Engineering Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build the Spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config('spark.jars.packages','saurfang:spark-sas7bdat:2.0.0-s_2.11').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will create an ETL pipeline for the [I94 immigration dataset](https://travel.trade.gov/research/reports/i94/historical/2016.html) and world temperature dataset from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data). This will analyst to explore the data to determine if immigration is affected by the destination's temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "[I94 immigration dataset](https://travel.trade.gov/research/reports/i94/historical/2016.html) was retrieved from from the US National Tourism and Trade Office's site: https://travel.trade.gov/research/reports/i94/historical/2016.html. The data are broken down into files by month. Below are some relevant information contained in the data for this particular project:\n",
    "\n",
    "* `i94yr`: Year (4 digit number)\n",
    "* `i94mon`: Month as numerical value (1 or 2 digit number)\n",
    "* `i94cit`: Reference code of the city of origin (3 digit number)\n",
    "* `i94port`: Reference code of destination city airport (3 characters)\n",
    "* `arrdate`: Arrival date (SAS Date)\n",
    "* `depdate`: Departure date (SAS Date)\n",
    "* `i94visa`: Reason for immigration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "[World temperature dataset](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) was retrieved from Kaggle: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data. The data are broken into separate files for different coarseness of areas (e.g. countries vs cities) but we'll specifically only look at cities. The file then specifies some of the following:\n",
    "\n",
    "* `dt`: Datetime of when temperature was recorded (YYYY-MM-DD)\n",
    "* `AverageTemperature`:  Average temperature in Celcius of area\n",
    "* `City`:  Name of city where temperature was recorded\n",
    "* `Country`:  Name of country where temperature was recorded\n",
    "* `Latitude`: Latitude of city\n",
    "* `Longitude`:  Longitude of city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### i94 Imigration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's start with the label description file to get an idea of what can be seen. It's formatted in such a way that we can parse though it to get just the column and its relevant description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "sas_label_description_file = '../../../data/I94_SAS_Labels_Descriptions.SAS'\n",
    "\n",
    "with open(sas_label_description_file) as f:\n",
    "    lines = f.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    I94YR:\n",
      "        4 digit year\n",
      "    \n",
      "    I94MON:\n",
      "        Numeric month\n",
      "    \n",
      "    I94CIT & I94RES:\n",
      "        This format shows all the valid and invalid codes for processing\n",
      "    \n",
      "    I94PORT:\n",
      "        This format shows all the valid and invalid codes for processing\n",
      "    \n",
      "    I94MODE:\n",
      "        There are missing values as well as not reported (9)\n",
      "    \n",
      "    I94BIR:\n",
      "        Age of Respondent in Years\n",
      "    \n",
      "    COUNT:\n",
      "        Used for summary statistics\n",
      "    \n",
      "    DTADFILE:\n",
      "        Character Date Field - Date added to I-94 Files - CIC does not use\n",
      "    \n",
      "    VISAPOST:\n",
      "        Department of State where where Visa was issued - CIC does not use\n",
      "    \n",
      "    OCCUP:\n",
      "        Occupation that will be performed in U.S. - CIC does not use\n",
      "    \n",
      "    ENTDEPA:\n",
      "        Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
      "    \n",
      "    ENTDEPD:\n",
      "        Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
      "    \n",
      "    ENTDEPU:\n",
      "        Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
      "    \n",
      "    MATFLAG:\n",
      "        Match flag - Match of arrival and departure records\n",
      "    \n",
      "    BIRYEAR:\n",
      "        4 digit year of birth\n",
      "    \n",
      "    DTADDTO:\n",
      "        Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\n",
      "    \n",
      "    GENDER:\n",
      "        Non-immigrant sex\n",
      "    \n",
      "    INSNUM:\n",
      "        INS number\n",
      "    \n",
      "    AIRLINE:\n",
      "        Airline used to arrive in U.S.\n",
      "    \n",
      "    ADMNUM:\n",
      "        Admission Number\n",
      "    \n",
      "    FLTNO:\n",
      "        Flight number of Airline used to arrive in U.S.\n",
      "    \n",
      "    VISATYPE:\n",
      "        Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
      "    "
     ]
    }
   ],
   "source": [
    "descriptions = [line for line in lines if '/*' in line and '*/\\n' in line]\n",
    "regex_code_description = re.compile(r'^/\\*\\s+(?P<code>.+?)\\s+-\\s+(?P<description>.+)\\s+\\*/$')\n",
    "matches = [regex_code_description.match(description) for description in descriptions]\n",
    "\n",
    "for match in matches:\n",
    "    print(f'''\n",
    "    {match.group(\"code\")}:\n",
    "        {match.group('description')}\n",
    "    ''', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We're particularly interested in the `I94PORT` since we'll cross reference this across the two sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "reg_abbrv_name = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "defined_ports = {}\n",
    "\n",
    "# Line after ports definition where ports are displayed\n",
    "for line in lines[302:961]:\n",
    "    match = reg_abbrv_name.search(line)\n",
    "    # Save 3 characted code → full name of port\n",
    "    defined_ports[match.group(1)]=match.group(2).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "sas_data_dir = '../../../data/18-83510-I94-Data-2016'\n",
    "# Get all files in the data directory\n",
    "sas_filenames = [f'{sas_data_dir}/{filename}' for filename in os.listdir(sas_data_dir)]\n",
    "sas_header_file = f'{sas_data_dir}/I94_SAS_Labels_Descriptions.SAS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94_spark = spark.read.format('com.github.saurfang.sas.spark').load(sas_filenames[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "To more easily explore the data, we'll load a Pandas DataFrame instead of Spark (though we'll use Spark later since it scales well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_as_pd_df(filepath, chunksize=20000, formatting='sas7bdat', encoding='ISO-8859-1'):\n",
    "    '''\n",
    "    Returns a Pandas DataFrame from a SAS formatted file with an option to read in the first chunk.\n",
    "    \n",
    "    Args:\n",
    "        filepath:   Path to SAS file.\n",
    "        chunksize:  The first n-lines to read in as a chunk. Can be `None` if whole file should be read.\n",
    "        formatting: Format of file.\n",
    "        encoding:   Encoding of file.\n",
    "    \n",
    "    Returns:\n",
    "        Pandas DataFrame of the SAS file.\n",
    "    \n",
    "    '''\n",
    "    # If a defined chunksize, just get the first chunk (size of chunksize)\n",
    "    if chunksize:\n",
    "        df_pandas = next(pd.read_sas(filepath, format=formatting, encoding=encoding, chunksize=chunksize))\n",
    "    # Executes if None (use the whole dataframe)\n",
    "    else:\n",
    "        # Note this can take some time as it's really big dataframe but it'd get the whole dataframe as a pandas \n",
    "        df_pandas = pd.read_sas(filepath, format=formatting, encoding=encoding, chunksize=None)\n",
    "        \n",
    "    return df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Only getting a chunk of the file to explore\n",
    "df_i94_pandas = read_as_pd_df(sas_filenames[0], chunksize=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 28 columns):\n",
      "cicid       500000 non-null float64\n",
      "i94yr       500000 non-null float64\n",
      "i94mon      500000 non-null float64\n",
      "i94cit      500000 non-null float64\n",
      "i94res      500000 non-null float64\n",
      "i94port     500000 non-null object\n",
      "arrdate     500000 non-null float64\n",
      "i94mode     499999 non-null float64\n",
      "i94addr     481570 non-null object\n",
      "depdate     481368 non-null float64\n",
      "i94bir      500000 non-null float64\n",
      "i94visa     500000 non-null float64\n",
      "count       500000 non-null float64\n",
      "dtadfile    499999 non-null object\n",
      "visapost    185656 non-null object\n",
      "occup       2121 non-null object\n",
      "entdepa     500000 non-null object\n",
      "entdepd     481368 non-null object\n",
      "entdepu     60 non-null object\n",
      "matflag     481368 non-null object\n",
      "biryear     500000 non-null float64\n",
      "dtaddto     499984 non-null object\n",
      "gender      429964 non-null object\n",
      "insnum      0 non-null object\n",
      "airline     499998 non-null object\n",
      "admnum      500000 non-null float64\n",
      "fltno       499999 non-null object\n",
      "visatype    500000 non-null object\n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 106.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_i94_pandas.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can observe some relevant columns that we'd like to investigate. We also notice that certain columns have many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  37.,   25.,   55.,   28.,    4.,   57.,   63.,   46.,   48.,\n",
       "         52.,   33.,   58.,   56.,   62.,   49.,   43.,   53.,   74.,\n",
       "         65.,   35.,   32.,   38.,   68.,   61.,   41.,   45.,   54.,\n",
       "         29.,   42.,   34.,   47.,   64.,   27.,   59.,   60.,   66.,\n",
       "         51.,   22.,   39.,   20.,   50.,   44.,   40.,   31.,   23.,\n",
       "         36.,    2.,    0.,   70.,   26.,   30.,   16.,   14.,   21.,\n",
       "         24.,    1.,   77.,   73.,   71.,    6.,   72.,    5.,   76.,\n",
       "         69.,   67.,    3.,   10.,   18.,   19.,   11.,   17.,    9.,\n",
       "          8.,   12.,   75.,    7.,   13.,   15.,   82.,   84.,   78.,\n",
       "         81.,   87.,   79.,   80.,   83.,   91.,   85.,   86.,   88.,\n",
       "         90.,   89.,   97.,   96.,   93.,   92.,  100.,   95.,   98.,\n",
       "         94.,   99.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0e74396198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e725afeb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_i94_pandas['i94bir'].unique())\n",
    "df_i94_pandas['i94bir'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We see ages seem reasonable and shouldn't be too concerning. But we remember that we are chunking the file, so we'll only keep rows that are defined from 0 to 100 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['XXX', 'ATL', 'WAS', 'NYC', 'TOR', 'BOS', 'HOU', 'MIA', 'CHI',\n",
       "       'LOS', 'CLT', 'DEN', 'DAL', 'DET', 'NEW', 'FTL', 'LVG', 'ORL',\n",
       "       'NOL', 'PIT', 'SFR', 'SPM', 'POO', 'PHI', 'SEA', 'SLC', 'TAM',\n",
       "       'HAM', 'NAS', 'VCV', 'MAA', 'AUS', 'HHW', 'OGG', 'PHO', 'SDP',\n",
       "       'SFB', 'EDA', 'MON', 'CLG', 'DUB', 'FMY', 'YGF', 'SAJ', 'CIN',\n",
       "       'BAL', 'RDU', 'WPB', 'STT', 'OAK', 'NSV', 'SNA', 'OTT', 'X96',\n",
       "       '5KE', 'CLE', 'HAR', 'PSP', 'CHR', 'HAL', 'SAA', 'KOA', 'SHA',\n",
       "       'WIN', 'BGM', 'NCA', 'OPF', 'SAI', 'JFA', 'AGA', 'ONT', 'CLM',\n",
       "       'STL', 'W55', 'CHS', 'SNJ', 'SRQ', 'ANC', 'LNB', 'LIH', 'MIL',\n",
       "       'INP', 'KAN', 'ROC', 'SAC', 'BRO', 'LAR', 'RNO', 'SGR', 'ELP',\n",
       "       'MCA', 'MDT', 'SPE', 'FPR', 'SYR', 'ICT', 'MLB', 'ADS', 'TUC',\n",
       "       'DLR', 'CAE', 'CHA', 'HSV', 'WIL', 'HPN', 'HEF', 'BRG', 'BED',\n",
       "       'DAB', 'JAC', 'FRB', 'SWF', 'KEY', 'PTK', 'MWH', 'X44', 'MYR',\n",
       "       'APF', 'ATW', 'PVD', 'BUF'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94_pandas['i94port'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We note that the value `XXX` is unknow as specified in the data header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We also note that the dates from the Spark DataFrame, the date formatted values were in SAS format. We'll have to convert those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv('data/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We'll likely want to keep all these columns (except `AverageTemperatureUncertainty`) though we note some rows are likely irrelevant to us such as cities that are not defined as ports in the i94 dataset.\n",
    "\n",
    "We also want to remove any missing temperature rows and duplicate rows (since we can't use that information effectively in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.235082e+06</td>\n",
       "      <td>8.235082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.672743e+01</td>\n",
       "      <td>1.028575e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035344e+01</td>\n",
       "      <td>1.129733e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.270400e+01</td>\n",
       "      <td>3.400000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.029900e+01</td>\n",
       "      <td>3.370000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.883100e+01</td>\n",
       "      <td>5.910000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.521000e+01</td>\n",
       "      <td>1.349000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.965100e+01</td>\n",
       "      <td>1.539600e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageTemperature  AverageTemperatureUncertainty\n",
       "count        8.235082e+06                   8.235082e+06\n",
       "mean         1.672743e+01                   1.028575e+00\n",
       "std          1.035344e+01                   1.129733e+00\n",
       "min         -4.270400e+01                   3.400000e-02\n",
       "25%          1.029900e+01                   3.370000e-01\n",
       "50%          1.883100e+01                   5.910000e-01\n",
       "75%          2.521000e+01                   1.349000e+00\n",
       "max          3.965100e+01                   1.539600e+01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We observe that minimum and maximum average temperatures range from about $-43^\\circ$ to $40^\\circ$ Celcius. Nothing seems out of the range of what's possible for the world so not much to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_i94(i94_spark_df):\n",
    "        '''\n",
    "        Cleans i94 Spark dataframe with readable column names and proper date\n",
    "        and value formats.\n",
    "        \n",
    "        Args:\n",
    "            i94_spark_df: Spark dataframe of data from i94 dataset.\n",
    "        \n",
    "        Returns:\n",
    "            Cleaned Spark dataframe of data from i94 dataset\n",
    "        '''\n",
    "        # Format dates\n",
    "        i94_spark_df_dates = (i94_spark_df\n",
    "                                .withColumn('arrival_year', col('i94yr').cast('integer'))\n",
    "                                .withColumn('arrival_month', col('i94mon').cast('integer'))\n",
    "                                .withColumn('data_base_sas', to_date(lit('01/01/1960'), 'MM/dd/yyyy'))\n",
    "                                .withColumn('arrival_date', expr('date_add(data_base_sas, arrdate)'))\n",
    "                                .withColumn('departure_date', expr('date_add(data_base_sas, depdate)'))\n",
    "                                .drop('arrdate', 'depdate')\n",
    "        )\n",
    "        \n",
    "        # Rename columns and set integer values\n",
    "        i94_spark_df_clean = (i94_spark_df_dates\n",
    "                                .withColumn('arrival_port', col('i94port'))                              \n",
    "                                .withColumn('departure_city', col('i94cit').cast('integer'))\n",
    "                                .withColumn('mode_of_travel', col('i94mode').cast('integer'))\n",
    "                                .withColumn('city_of_origin', col('i94cit').cast('integer'))\n",
    "                                .withColumn('country_of_origin', col('i94res').cast('integer'))\n",
    "                                .withColumn('age', col('i94bir').cast('integer'))\n",
    "                                .withColumn('visa_type', col('i94visa').cast('integer'))            \n",
    "        )\n",
    "        \n",
    "        # Final selection of data and order\n",
    "        i94_spark_df_final = i94_spark_df_clean.select(\n",
    "                    col('arrival_date'),\n",
    "                    col('departure_date'),\n",
    "                    col('arrival_port'),\n",
    "                    col('city_of_origin'),\n",
    "                    col('country_of_origin'),\n",
    "                    col('mode_of_travel'),\n",
    "                    col('age'),\n",
    "                    col('visa_type')\n",
    "                )\n",
    "        \n",
    "        return i94_spark_df_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+------------+--------------+-----------------+--------------+---+---------+\n",
      "|arrival_date|departure_date|arrival_port|city_of_origin|country_of_origin|mode_of_travel|age|visa_type|\n",
      "+------------+--------------+------------+--------------+-----------------+--------------+---+---------+\n",
      "|  2016-04-29|          null|         XXX|           692|              692|          null| 37|        2|\n",
      "|  2016-04-07|          null|         ATL|           254|              276|             1| 25|        3|\n",
      "|  2016-04-01|    2016-08-25|         WAS|           101|              101|             1| 55|        2|\n",
      "|  2016-04-01|    2016-04-23|         NYC|           101|              101|             1| 28|        2|\n",
      "|  2016-04-01|    2016-04-23|         NYC|           101|              101|             1|  4|        2|\n",
      "+------------+--------------+------------+--------------+-----------------+--------------+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94_clean = clean_i94(df_i94_spark)\n",
    "df_i94_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf()\n",
    "def city_to_port(city_name):\n",
    "    '''\n",
    "    Check city name against defined ports and return the used port abbreviation.\n",
    "    \n",
    "    Args:\n",
    "        city_name: Name of city.\n",
    "    \n",
    "    Returns:\n",
    "        Abbreviation if found otherwise nothing will return (None).\n",
    "    '''\n",
    "    for abbrv,port_name in defined_ports.values():\n",
    "        # Checking if city is contained in the official city port name from i94 data\n",
    "        if city_name.lower() in port_name.lower():\n",
    "            return abbrv\n",
    "\n",
    "def clean_temp_data(df):\n",
    "    '''\n",
    "    Returns a clean temperature Spark DataFrame.\n",
    "    '''\n",
    "    new_df = df.filter(df['AverageTemperature'] != 'NaN').dropDuplicates(['City', 'Country'])\n",
    "    new_df = new_df.withColumn('port', city_to_port(new_df['City']))\n",
    "    new_df = new_df.filter(new_df['port'] != 'null')\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df_spark = spark.read.format(\"csv\").option(\"header\", \"true\").load('data/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_df_spark_clean = clean_temp_data(temp_df_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`fact_immigration` gives us the main facts that can be used for queries. Below are the columns in the fact table:\n",
    "\n",
    "* `arrival_date`: Arrival date of immigrant \n",
    "* `departure_date`: Departure date of immigrant\n",
    "* `arrival_port`:  Arrival port (3 character code)\n",
    "* `city_of_origin`: City immigrated from (2 digit code)\n",
    "* `country_of_origin`: Country immigrated from\n",
    "* `mode_of_travel`: How immigration occurred (1 digit code or null)\n",
    "* `age`: Age of immigrant (years old)\n",
    "* `visa_type`: Visa code (1 digit: Business/Pleasure/Student)\n",
    "* `AveargeTemperature`: Average temperature of city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`dim_immigration` provides some of the relevant information from the i94 dataste.\n",
    "\n",
    "Columns:\n",
    "* `arrival_date`: Arrival date of immigrant \n",
    "* `departure_date`: Departure date of immigrant\n",
    "* `arrival_port`:  Arrival port (3 character code)\n",
    "* `city_of_origin`: City immigrated from (2 digit code)\n",
    "* `country_of_origin`: Country immigrated from\n",
    "* `mode_of_travel`: How immigration occurred (1 digit code or null)\n",
    "* `age`: Age of immigrant (years old)\n",
    "* `visa_type`: Visa code (1 digit: Business/Pleasure/Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`dim_temperature` provides the columns from the global temperature dataset.\n",
    "\n",
    "Columns:\n",
    "* `port`: i94 code of port for city\n",
    "* `City`: Name of city\n",
    "* `Country`: Name of city's country\n",
    "* `AverageTemperature`: Average temperature of city\n",
    "* `Latitude`: Latitude of city\n",
    "* `Longitude` Longitude of city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. Data processing/cleaning\n",
    "2. Create the dimension table from i94 dataset\n",
    "3. Create the dimension table from global temperature dataset\n",
    "4. Create fact table from dimension tables by joining on the arrival port of `dim_immigration` and the port for `dim_temperature`\n",
    "5. Write to parquet file partitioned by the port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
